{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5613221,"sourceType":"datasetVersion","datasetId":3163593}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import train_test_split\n\ndef load_images_and_masks(img_folder, mask_folder, img_size=(256, 256)):\n    # Filter out .txt files or any unwanted files\n    img_filenames = [f for f in sorted(os.listdir(img_folder)) if not f.endswith('.txt')]\n    mask_filenames = [f for f in sorted(os.listdir(mask_folder)) if not f.endswith('.txt')]\n    \n    images = []\n    masks = []\n    \n    for img_filename, mask_filename in zip(img_filenames, mask_filenames):\n        img_path = os.path.join(img_folder, img_filename)\n        mask_path = os.path.join(mask_folder, mask_filename)\n        \n        # Load image and mask\n        img = load_img(img_path, target_size=img_size)\n        img = img_to_array(img) / 255.0\n        mask = load_img(mask_path, target_size=img_size, color_mode=\"grayscale\")\n        mask = img_to_array(mask) / 255.0\n        \n        images.append(img)\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks)\n\n# Paths to the dataset\ntrain_img_folder_path = \"/kaggle/input/isic-2018/data/images/train\"\ntrain_mask_folder_path = \"/kaggle/input/isic-2018/data/annotations/train\"\nval_img_folder_path = \"/kaggle/input/isic-2018/data/images/val\"\nval_mask_folder_path = \"/kaggle/input/isic-2018/data/annotations/val\"\ntest_img_folder_path = \"/kaggle/input/isic-2018/data/images/test\"\ntest_mask_folder_path = \"/kaggle/input/isic-2018/data/annotations/test\"\n\n# Load datasets\ntrain_imgs, train_masks = load_images_and_masks(train_img_folder_path, train_mask_folder_path)\nval_imgs, val_masks = load_images_and_masks(val_img_folder_path, val_mask_folder_path)\ntest_imgs, test_masks = load_images_and_masks(test_img_folder_path, test_mask_folder_path)\n\n# Build the enhanced U-Net model\ndef conv_block(input_tensor, num_filters):\n    x = layers.Conv2D(num_filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(input_tensor)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n    x = layers.Conv2D(num_filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n    return x\n\ndef residual_block(input_tensor, num_filters):\n    conv = conv_block(input_tensor, num_filters)\n    res = layers.Conv2D(num_filters, (1, 1), padding=\"same\")(input_tensor)\n    output = layers.add([conv, res])\n    return output\n\ndef attention_block(g, x, num_filters):\n    g1 = layers.Conv2D(num_filters, (1, 1), padding=\"same\")(g)\n    g1 = layers.BatchNormalization()(g1)\n    x1 = layers.Conv2D(num_filters, (1, 1), padding=\"same\")(x)\n    x1 = layers.BatchNormalization()(x1)\n    psi = layers.Activation(\"relu\")(layers.add([g1, x1]))\n    psi = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(psi)\n    return layers.multiply([x, psi])\n\ndef build_enhanced_unet(input_shape=(256, 256, 3), num_classes=1):\n    inputs = layers.Input(input_shape)\n\n    # Encoder\n    f1 = residual_block(inputs, 64)\n    p1 = layers.MaxPooling2D((2, 2))(f1)\n    p1 = layers.Dropout(0.1)(p1)\n\n    f2 = residual_block(p1, 128)\n    p2 = layers.MaxPooling2D((2, 2))(f2)\n    p2 = layers.Dropout(0.1)(p2)\n\n    f3 = residual_block(p2, 256)\n    p3 = layers.MaxPooling2D((2, 2))(f3)\n    p3 = layers.Dropout(0.2)(p3)\n\n    f4 = residual_block(p3, 512)\n    p4 = layers.MaxPooling2D((2, 2))(f4)\n    p4 = layers.Dropout(0.2)(p4)\n\n    # Bottleneck\n    bottleneck = residual_block(p4, 1024)\n    bottleneck = layers.Dropout(0.3)(bottleneck)\n\n    # Decoder\n    u4 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(bottleneck)\n    a4 = attention_block(u4, f4, 512)\n    c4 = residual_block(a4, 512)\n\n    u3 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(c4)\n    a3 = attention_block(u3, f3, 256)\n    c3 = residual_block(a3, 256)\n\n    u2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c3)\n    a2 = attention_block(u2, f2, 128)\n    c2 = residual_block(a2, 128)\n\n    u1 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c2)\n    a1 = attention_block(u1, f1, 64)\n    c1 = residual_block(a1, 64)\n\n    outputs = layers.Conv2D(num_classes, (1, 1), activation=\"sigmoid\")(c1)\n\n    model = models.Model(inputs, outputs)\n    return model\n\nmodel = build_enhanced_unet(input_shape=(256, 256, 3), num_classes=1)\n\n\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T05:19:17.738463Z","iopub.execute_input":"2025-09-19T05:19:17.738807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile and train the model\nmodel = build_enhanced_unet(input_shape=(256, 256, 3))\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\", tf.keras.metrics.MeanIoU(num_classes=2)])\n\ncheckpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n\nhistory = model.fit(\n    train_imgs, train_masks,\n    validation_data=(val_imgs, val_masks),\n    epochs=50,\n    batch_size=16,\n    callbacks=[checkpoint, early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on test data\ntest_loss, test_accuracy, test_miou = model.evaluate(test_imgs, test_masks, batch_size=16)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Mean IoU: {test_miou:.4f}\")\n\n# Predict on test images\npredictions = model.predict(test_imgs)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-17T15:20:50.308875Z","iopub.status.idle":"2025-09-17T15:20:50.309318Z","shell.execute_reply.started":"2025-09-17T15:20:50.309093Z","shell.execute_reply":"2025-09-17T15:20:50.309116Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to display original image, ground truth mask, and predicted mask\ndef display_predictions(images, masks, predictions, num_samples=5):\n    for i in range(num_samples):\n        plt.figure(figsize=(12, 4))\n        \n        # Original image\n        plt.subplot(1, 3, 1)\n        plt.imshow(images[i])\n        plt.title(\"Original Image\")\n        plt.axis(\"off\")\n        \n        # Ground truth mask\n        plt.subplot(1, 3, 2)\n        plt.imshow(masks[i].squeeze(), cmap=\"gray\")\n        plt.title(\"Ground Truth Mask\")\n        plt.axis(\"off\")\n        \n        # Predicted mask\n        plt.subplot(1, 3, 3)\n        plt.imshow(predictions[i].squeeze(), cmap=\"gray\")\n        plt.title(\"Predicted Mask\")\n        plt.axis(\"off\")\n        \n        plt.show()\n\n# Generate predictions\npredictions = model.predict(test_imgs)\npredictions = (predictions > 0.5).astype(np.uint8)  # Apply threshold to get binary masks\n\n# Display predictions\ndisplay_predictions(test_imgs, test_masks, predictions, num_samples=5)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-17T15:20:50.310653Z","iopub.status.idle":"2025-09-17T15:20:50.311086Z","shell.execute_reply.started":"2025-09-17T15:20:50.310850Z","shell.execute_reply":"2025-09-17T15:20:50.310871Z"},"trusted":true},"outputs":[],"execution_count":null}]}